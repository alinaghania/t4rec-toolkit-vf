import transformers4rec.torch as tr
from transformers4rec.torch.model.head import Head
from transformers4rec.config.model import XLNetConfig
from transformers4rec.torch.masking import MaskSequence
from transformers4rec.torch.utils import schema_utils
from transformers4rec.torch.models.sequential import NextItemPredictionTask
from merlin.schema import Schema, Tags, ColumnSchema
import pandas as pd
import numpy as np
import torch
from torch.utils.data import DataLoader
from merlin.io import Dataset
from transformers4rec.torch.utils.examples_utils import generate_schema

from transformers4rec.torch.metrics.ranking import NDCGAt, RecallAt

print("üöÄ T4REC XLNET - FEATURES CAT√âGORIELLES UNIQUEMENT - STABLE")
print("="*65)

# -----------------------
# 1. Cr√©ation du sch√©ma
# -----------------------
print("üìã Cr√©ation du sch√©ma cat√©goriel...")

schema = Schema([
    ColumnSchema("item_id", tags=[Tags.ITEM_ID, Tags.CATEGORICAL]),
    ColumnSchema("user_category", tags=[Tags.USER, Tags.CATEGORICAL])
])
print(f"‚úÖ Sch√©ma d√©fini avec {len(schema.column_names)} colonnes: {schema.column_names}")

# -----------------------
# 2. Donn√©es d'exemple
# -----------------------
print("üìä G√©n√©ration de donn√©es d'exemple...")

num_samples = 560
max_session_len = 20
item_ids = np.random.randint(1, 100, size=(num_samples,))
user_cats = np.random.choice([f"cat_{i}" for i in range(1, 15)], size=(num_samples,))
session_id = np.repeat(np.arange(num_samples // max_session_len), max_session_len)

df = pd.DataFrame({
    "item_id": item_ids,
    "user_category": user_cats,
    "session_id": session_id
})

dataset = Dataset(df)
print(f"‚úÖ Donn√©es pr√™tes: item_id ({df['item_id'].nunique()} uniques), user_category ({df['user_category'].nunique()} uniques)")

# -----------------------
# 3. Module d'entr√©e
# -----------------------
print("üèóÔ∏è Construction du module d'entr√©e...")

input_module = tr.TabularSequenceFeatures.from_schema(
    schema,
    max_sequence_length=max_session_len,
    continuous_projection=None,
    aggregation="concat",
)

print("‚úÖ Module d'entr√©e: TabularSequenceFeatures")

# -----------------------
# 4. Masking
# -----------------------
print("üé≠ Configuration du masking...")

masking = MaskSequence(max_sequence_length=max_session_len)
input_module.masking = masking

print("‚úÖ Masking activ√©: MaskSequence")

# -----------------------
# 5. XLNet config
# -----------------------
print("‚öôÔ∏è Configuration du mod√®le XLNet...")

xlnet_config = XLNetConfig.build(
    d_model=128,
    n_head=4,
    n_layer=2,
    total_seq_length=max_session_len,
)

print("‚úÖ XLNet configur√©: 128d, 4 heads, 2 layers")

# -----------------------
# 6. Body du mod√®le
# -----------------------
print("üß± Construction du corps du mod√®le...")

transformer_block = tr.Block(
    tr.TransformerBlock(xlnet_config, masking=input_module.masking),
    output_size=128  # Important!
)

body = tr.SequentialBlock(
    input_module,
    transformer_block
)

print("‚úÖ Corps du mod√®le pr√™t: SequentialBlock")

# -----------------------
# 7. Head
# -----------------------
print("üß† Ajout de la t√™te NextItemPredictionTask...")

try:
    head = Head(
        body,
        NextItemPredictionTask(
            weight_tying=True,
            metrics=[
                NDCGAt(top_ks=[5, 10], labels_onehot=True),
                RecallAt(top_ks=[5, 10], labels_onehot=True)
            ],
            loss_function="cross_entropy"
        ),
        inputs=input_module
    )
    print("‚úÖ T√™te ajout√©e avec succ√®s !")
except Exception as e:
    print("‚ùå ERREUR G√âN√âRALE :", str(e))
    print("üìë Sch√©ma avec", len(schema.column_names), "colonnes :", schema.column_names)
    raise
