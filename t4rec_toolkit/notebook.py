# üöÄ T4REC XLNET - FEATURES CAT√âGORIELLES UNIQUEMENT - STABLE
print("üöÄ T4REC XLNET - FEATURES CAT√âGORIELLES UNIQUEMENT - STABLE")
print("=" * 65)

import torch
import transformers4rec.torch as tr
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

try:
    # === CONFIGURATION ===
    CONFIG = {
        'd_model': 128,
        'n_head': 4,
        'n_layer': 2,
        'max_sequence_length': 15,
        'mem_len': 30,
        'dropout': 0.1,
        'hidden_size': 128  # Pour MaskSequence
    }

    # === SCH√âMA T4REC ===
    print("üìã Cr√©ation du sch√©ma cat√©goriel...")

    from merlin.schema import Schema, ColumnSchema, Tags

    columns = [
        ColumnSchema("item_id", tags=[Tags.CATEGORICAL, Tags.ITEM, Tags.ID],
                     dtype=np.int32, properties={"domain": {"min": 1, "max": 100}}),
        ColumnSchema("user_category", tags=[Tags.CATEGORICAL, Tags.USER],
                     dtype=np.int32, properties={"domain": {"min": 1, "max": 20}})
    ]

    schema = Schema(columns)
    print(f"‚úÖ Sch√©ma d√©fini avec {len(schema)} colonnes: {[col.name for col in schema]}")

    # === DONN√âES DUMMY ===
    print("\nüìä G√©n√©ration de donn√©es d'exemple...")

    n_samples = 560
    item_ids = np.arange(n_samples) % 99 + 1
    user_categories = np.random.randint(1, 15, n_samples)

    t4rec_data = {
        "item_id": item_ids.astype(np.int64),
        "user_category": user_categories.astype(np.int64)
    }

    print(f"‚úÖ Donn√©es pr√™tes: item_id ({len(np.unique(item_ids))} uniques), user_category ({len(np.unique(user_categories))} uniques)")

    # === MODULE D'ENTR√âE ===
    print("\nüèóÔ∏è Construction du module d'entr√©e...")

    input_module = tr.TabularSequenceFeatures.from_schema(
        schema=schema,
        max_sequence_length=CONFIG['max_sequence_length'],
        aggregation="concat",
        masking=None,
        automatic_build=False
    )
    print(f"‚úÖ Module d'entr√©e: {type(input_module).__name__}")

    # === MASKING ===
    print("\nüé≠ Configuration du masking...")

    from transformers4rec.torch.masking import MaskSequence

    try:
        masking_module = MaskSequence(
            schema=schema.select_by_tag(Tags.ITEM),
            hidden_size=CONFIG['hidden_size'],
            max_sequence_length=CONFIG['max_sequence_length'],
            masking_prob=0.2,
            padding_idx=0
        )
        input_module.masking = masking_module
        print(f"‚úÖ Masking activ√©: {type(masking_module).__name__}")
    except Exception as err:
        print(f"‚ö†Ô∏è Erreur masking: {err}")
        input_module.masking = None

    # === CONFIGURATION XLNET ===
    print("\n‚öôÔ∏è Configuration du mod√®le XLNet...")

    xlnet_config = tr.XLNetConfig.build(
        d_model=CONFIG['d_model'],
        n_head=CONFIG['n_head'],
        n_layer=CONFIG['n_layer'],
        total_seq_length=CONFIG['max_sequence_length'],
        mem_len=CONFIG['mem_len'],
        dropout=CONFIG['dropout'],
        attn_type='bi',
        initializer_range=0.02,
        hidden_act='gelu',
        layer_norm_eps=1e-12
    )

    print(f"‚úÖ XLNet configur√©: {CONFIG['d_model']}d, {CONFIG['n_head']} heads, {CONFIG['n_layer']} layers")

    # === CORPS DU MOD√àLE ===
    print("\nüß± Construction du corps du mod√®le...")

    transformer_block = tr.Block(
        tr.TransformerBlock(xlnet_config, masking=input_module.masking),
        output_size=CONFIG['d_model']
    )

    body = tr.SequentialBlock(
        input_module,
        transformer_block
    )

    print(f"‚úÖ Corps du mod√®le pr√™t: {type(body).__name__}")

    # === T√äTE DU MOD√àLE ===
    print("\nüß† Ajout de la t√™te NextItemPredictionTask...")

    from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt

    task = tr.NextItemPredictionTask(
        weight_tying=True,
        metrics=[
            NDCGAt(top_ks=[5, 10], labels_onehot=True),
            RecallAt(top_ks=[5, 10], labels_onehot=True)
        ],
        loss_function="cross_entropy"
    )

    head = tr.Head(
        body=body,
        task=task,
        inputs=input_module
    )

    # === MOD√àLE FINAL ===
    print("\nüöÄ Initialisation du mod√®le T4Rec...")

    model = tr.Model(head)

    n_params = sum(p.numel() for p in model.parameters())
    print(f"‚úÖ Mod√®le T4Rec construit avec {n_params:,} param√®tres")

    # === TEST AVEC BATCH DUMMY ===
    print("\nüß™ Test du mod√®le sur un batch...")

    batch_size = 16
    sequenced_batch = {}

    for key, data in t4rec_data.items():
        tensor = torch.tensor(data[:batch_size], dtype=torch.long)
        seq_tensor = tensor.unsqueeze(1).expand(-1, CONFIG['max_sequence_length'])
        sequenced_batch[key] = seq_tensor

    print(f"üì¶ Batch de test: {[(k, v.shape) for k, v in sequenced_batch.items()]}")

    model.eval()
    with torch.no_grad():
        try:
            output = model(sequenced_batch)
            print(f"‚úÖ Test r√©ussi ! Output shape: {output.shape}")
        except Exception as e:
            print(f"‚ùå Test √©chou√© : {e}")
            import traceback
            traceback.print_exc()

except Exception as e:
    print(f"\n‚ùå ERREUR G√âN√âRALE : {e}")
    import traceback
    traceback.print_exc()
    if 'schema' in locals():
        try:
            print(f"üìë Sch√©ma avec {len(schema)} colonnes : {[col.name for col in schema]}")
        except Exception as debug_err:
            print(f"‚ö†Ô∏è Impossible d'acc√©der aux colonnes : {debug_err}")

