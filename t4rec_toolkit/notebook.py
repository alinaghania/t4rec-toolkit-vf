# === T4REC XLNET AVEC MODULE CAT√âGORIEL CORRECT ===

print("üöÄ T4REC XLNET - MODULE CAT√âGORIEL")
print("=" * 40)

import torch
import transformers4rec.torch as tr
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

try:
    # Configuration T4Rec
    CONFIG = {
        'd_model': 128,
        'n_head': 4,
        'n_layer': 2,
        'max_sequence_length': 15,
        'mem_len': 30,
        'dropout': 0.1
    }

    # 1. Cr√©er le sch√©ma T4Rec avec focus sur les cat√©gorielles
    print("üìã Sch√©ma T4Rec avec cat√©gorielles...")
    
    from merlin.schema import Schema, ColumnSchema, Tags
    
    # Le sch√©ma DOIT avoir l'item_id comme PREMI√àRE colonne cat√©gorielle
    columns = [
        # Item ID - OBLIGATOIREMENT en premier
        ColumnSchema(
            name="item_id",
            tags={Tags.CATEGORICAL, Tags.ITEM, Tags.ID},
            dtype="int64",
            properties={"vocab_size": 100}  # R√©duit pour simplifier
        ),
        # Autres features cat√©gorielles (contexte)
        ColumnSchema(
            name="user_category",
            tags={Tags.CATEGORICAL, Tags.USER},
            dtype="int64", 
            properties={"vocab_size": 20}
        ),
        # Features continues EN DERNIER
        ColumnSchema(
            name="continuous_feature",
            tags={Tags.CONTINUOUS},
            dtype="float32",
            properties={}
        )
    ]
    
    schema = Schema(columns)
    print(f"‚úÖ Sch√©ma: item_id + user_category + continuous")
    
    # 2. Donn√©es optimis√©es pour T4Rec
    print("\nüìä Donn√©es pour T4Rec...")
    
    # Prendre le nombre d'√©chantillons
    n_samples = len(next(iter(tabular_data.values())))
    print(f"√âchantillons: {n_samples}")
    
    # Item IDs : cycle sur une petite plage
    item_ids = np.arange(n_samples) % 99 + 1  # IDs de 1 √† 99
    
    # User categories : bas√© sur vos features dummy
    categorical_names = [name for name in tabular_data.keys() if 'dummy' in name]
    if categorical_names:
        base_cat = np.array(tabular_data[categorical_names[0]])
        user_categories = (base_cat % 19) + 1  # 1 √† 19
    else:
        user_categories = np.random.randint(1, 20, n_samples)
    
    # Feature continue : moyenne de vos features
    sequence_names = [name for name in tabular_data.keys() if 'sequence' in name]
    if sequence_names:
        # Prendre la moyenne des premi√®res valeurs des s√©quences
        continuous_vals = []
        for name in sequence_names[:2]:  # Max 2 features
            data = tabular_data[name]
            if isinstance(data[0], np.ndarray):
                vals = [seq[0] if len(seq) > 0 else 0.0 for seq in data]
            else:
                vals = data
            continuous_vals.append(vals)
        continuous_feature = np.mean(continuous_vals, axis=0).astype(np.float32)
    else:
        continuous_feature = np.random.randn(n_samples).astype(np.float32)
    
    # Dataset T4Rec
    t4rec_data = {
        "item_id": item_ids.astype(np.int64),
        "user_category": user_categories.astype(np.int64), 
        "continuous_feature": continuous_feature
    }
    
    print(f"‚úÖ item_id: {len(np.unique(item_ids))} uniques ({item_ids.min()}-{item_ids.max()})")
    print(f"‚úÖ user_category: {len(np.unique(user_categories))} uniques") 
    print(f"‚úÖ continuous_feature: shape={continuous_feature.shape}")
    
    # 3. Cr√©er le module d'entr√©e SANS masking d'abord
    print("\nüèóÔ∏è Module d'entr√©e sans masking...")
    
    # √âtape 1: Cr√©er sans masking pour √©viter l'erreur
    input_module = tr.TabularSequenceFeatures.from_schema(
        schema=schema,
        max_sequence_length=CONFIG['max_sequence_length'],
        continuous_projection=CONFIG['d_model'],
        aggregation="concat",
        masking=None  # PAS de masking initially
    )
    
    print(f"‚úÖ Module cr√©√©: {type(input_module).__name__}")
    
    # √âtape 2: Ajouter le masking manuellement
    from transformers4rec.torch.masking import MaskSequence
    
    # Cr√©er le masking manuellement
    masking_module = MaskSequence(
        schema=schema.select_by_tag(Tags.ITEM),  # Seulement item_id
        max_sequence_length=CONFIG['max_sequence_length'],
        masking_prob=0.2
    )
    
    # Assigner le masking au module
    input_module.masking = masking_module
    
    print(f"‚úÖ Masking assign√©: {type(masking_module).__name__}")
    
    # 4. Configuration XLNet
    print("\n‚öôÔ∏è Config XLNet...")
    
    xlnet_config = tr.XLNetConfig.build(
        d_model=CONFIG['d_model'],
        n_head=CONFIG['n_head'], 
        n_layer=CONFIG['n_layer'],
        total_seq_length=CONFIG['max_sequence_length'],
        mem_len=CONFIG['mem_len'],
        dropout=CONFIG['dropout']
    )
    
    print(f"‚úÖ XLNet: {CONFIG['d_model']}d, {CONFIG['n_head']}h, {CONFIG['n_layer']}l")
    
    # 5. Construire le mod√®le
    print("\nüöÄ Mod√®le T4Rec...")
    
    # Corps du mod√®le
    body = tr.SequentialBlock(
        input_module,
        tr.TransformerBlock(xlnet_config, masking=input_module.masking)
    )
    
    # T√™te de pr√©diction
    head = tr.Head(
        body,
        tr.NextItemPredictionTask(weight_tying=True),
        inputs=input_module
    )
    
    # Mod√®le complet
    model = tr.Model(head)
    
    print(f"‚úÖ Mod√®le T4Rec cr√©√©!")
    print(f"üìà Param√®tres: {sum(p.numel() for p in model.parameters()):,}")
    
    # 6. Test rapide du mod√®le
    print("\nüß™ Test du mod√®le...")
    
    # Cr√©er un batch test
    test_batch = {
        k: torch.tensor(v[:16]) for k, v in t4rec_data.items()  # 16 premiers √©chantillons
    }
    
    model.eval()
    with torch.no_grad():
        try:
            output = model(test_batch)
            print(f"‚úÖ Test r√©ussi: output shape={output.shape}")
            test_success = True
        except Exception as test_error:
            print(f"‚ùå Test √©chou√©: {test_error}")
            test_success = False
    
    if test_success:
        # 7. Entra√Ænement
        print("\nüéØ Entra√Ænement...")
        
        # Pr√©parer les donn√©es
        X_torch = {k: torch.tensor(v) for k, v in t4rec_data.items()}
        
        # Target
        y = df['souscription_produit_1m'].values
        label_encoder = LabelEncoder() 
        y_encoded = label_encoder.fit_transform(y)
        y_torch = torch.tensor(y_encoded, dtype=torch.long)
        
        # Split
        indices = np.arange(len(y_torch))
        train_indices, val_indices = train_test_split(
            indices, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        X_train = {k: v[train_indices] for k, v in X_torch.items()}
        X_val = {k: v[val_indices] for k, v in X_torch.items()}
        y_train = y_torch[train_indices] 
        y_val = y_torch[val_indices]
        
        print(f"‚úÖ Train: {len(train_indices)}, Val: {len(val_indices)}")
        
        # Optimiseur
        from torch.optim import AdamW
        from torch.nn import CrossEntropyLoss
        
        optimizer = AdamW(model.parameters(), lr=1e-4)
        criterion = CrossEntropyLoss()
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        
        # Entra√Ænement
        num_epochs = 8
        batch_size = 32
        
        print(f"Device: {device}, √âpoques: {num_epochs}")
        
        for epoch in range(num_epochs):
            model.train()
            total_loss = 0
            batches = 0
            
            for i in range(0, len(train_indices), batch_size):
                batch_indices = train_indices[i:i+batch_size]
                
                batch_X = {k: v[batch_indices].to(device) for k, v in X_train.items()}
                batch_y = y_train[i:i+batch_size].to(device)
                
                optimizer.zero_grad()
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                batches += 1
            
            avg_loss = total_loss / batches if batches > 0 else 0
            print(f"√âpoque {epoch+1}: Loss={avg_loss:.4f}")
        
        # √âvaluation
        print("\nüìä √âvaluation...")
        
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for i in range(0, len(val_indices), batch_size):
                batch_indices = val_indices[i:i+batch_size]
                
                batch_X = {k: v[batch_indices].to(device) for k, v in X_val.items()}
                batch_y = y_val[i:i+batch_size].to(device)
                
                outputs = model(batch_X)
                predictions = torch.argmax(outputs, dim=1)
                correct += (predictions == batch_y).sum().item()
                total += batch_y.size(0)
        
        accuracy = correct / total if total > 0 else 0
        print(f"‚úÖ Accuracy: {accuracy:.2%}")
        
        # Sauvegarde
        torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'schema': schema,
            'config': CONFIG,
            'label_encoder': label_encoder,
            'accuracy': accuracy,
            't4rec_data_keys': list(t4rec_data.keys())
        }, 't4rec_xlnet_success.pth')
        
        print("‚úÖ Mod√®le sauv√©: t4rec_xlnet_success.pth")
        print("üéâ SUCC√àS T4REC XLNET!")
    
    else:
        print("‚ùå Test du mod√®le √©chou√© - pas d'entra√Ænement")

except Exception as e:
    print(f"‚ùå ERREUR: {e}")
    import traceback
    traceback.print_exc()
    
    # Debug d√©taill√©
    print(f"\nüîç DEBUG:")
    if 'input_module' in locals():
        print(f"Input module: {type(input_module)}")
        print(f"Input module hasattr masking: {hasattr(input_module, 'masking')}")
        if hasattr(input_module, 'masking'):
            print(f"Masking type: {type(input_module.masking)}")
    
    if 'xlnet_config' in locals():
        print(f"XLNet config: {type(xlnet_config)}")
    
    print(f"Sch√©ma colonnes: {[col.name for col in schema.columns] if 'schema' in locals() else 'Non cr√©√©'}")
